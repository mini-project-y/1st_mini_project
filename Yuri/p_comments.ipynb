{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DB에 저장된 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn = pymysql.connect(host=\"localhost\", port=3306, db=\"project\", \n",
    "#                        user=\"humanda\", password=\"humanda\")\n",
    "\n",
    "\n",
    "# sql3 = \"select * from transportation\"\n",
    "\n",
    "# transportation = pd.read_sql_query(sql3, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "미세먼지 농도 범위에 따른 데이터프레임 분리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good_df = fine_dust[fine_dust['fine_dust(㎍/㎥)'] <= 30]\n",
    "# normal_df = fine_dust[(fine_dust['fine_dust(㎍/㎥)'] > 30) & (fine_dust['fine_dust(㎍/㎥)'] <= 80)]\n",
    "# bad_df = fine_dust[(fine_dust['fine_dust(㎍/㎥)'] > 80) & (fine_dust['fine_dust(㎍/㎥)'] <= 150)]\n",
    "# very_bad_df = fine_dust[fine_dust['fine_dust(㎍/㎥)'] > 150]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DF 조건주기 (np.where or np.select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.delftstack.com/ko/howto/python-pandas/how-to-create-dataframe-column-based-on-given-condition-in-pandas/\n",
    "\n",
    "# np.where(condition, x, y)는 조건이 충족되면x를, 그렇지 않으면y를 반환\n",
    "# 예제) df[\"Status\"] = np.where(df[\"Salary\"] >= 400, \"Senior\", \"Junior\")\n",
    "# salary가 400 이상이면 status 컬럼에 senior를, 미만이라면 junior를 입력\n",
    "\n",
    "# np.where()는 조건 목록과 선택 목록을 입력으로 받아서 조건에 따라 선택 목록의 요소로 구성된 배열을 반환\n",
    "# 이 방법을 사용하면 두 개 이상의 조건이있을 때 Pandas의 주어진 조건을 기반으로 DataFrame 열을 만듦\n",
    "# 예제\n",
    "# conditionlist = [                                 # 조건들을 담는 변수명 = []\n",
    "#     (df[\"Salary\"] >= 500),                        # 조건1 salary는 500 이상\n",
    "#     (df[\"Salary\"] >= 300) & (df[\"Salary\"] < 300), # 조건2 salary는 300 이상, 300미만?\n",
    "#     (df[\"Salary\"] <= 300),                        # 조건3 salary는 300 이하\n",
    "# ]\n",
    "# choicelist = [\"High\", \"Mid\", \"Low\"]               # 값 이름 변수 = [조건1의 값, 조건2의 값, 조건3의 값]\n",
    "# df[\"Salary_Range\"] = np.select(conditionlist, choicelist, default=\"Not Specified\")\n",
    "# df[\"새로운컬럼이름\"] = np.select(조건변수명, 값이름변수, default=\"조건미충족시 표시할 이름\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "미세먼지 등급 매기기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 조건 설정\n",
    "# conditions = [\n",
    "#     (fine_dust['fine_dust(㎍/㎥)'] <= 30),\n",
    "#     (fine_dust['fine_dust(㎍/㎥)'] > 30) & (fine_dust['fine_dust(㎍/㎥)'] <= 80),\n",
    "#     (fine_dust['fine_dust(㎍/㎥)'] > 80) & (fine_dust['fine_dust(㎍/㎥)'] <= 150),\n",
    "#     (fine_dust['fine_dust(㎍/㎥)'] > 150)\n",
    "# ]\n",
    "\n",
    "# # 각 조건에 따른 값\n",
    "# values = ['good', 'normal', 'bad', 'very_bad']\n",
    "\n",
    "# # 새로운 'grade' 컬럼 추가 (default 값을 설정해 오류 해결)\n",
    "# fine_dust['grade'] = np.select(conditions, values, default='unknown')\n",
    "\n",
    "# # 결과 확인\n",
    "# fine_dust.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "판다스 datetime 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"신컬럼명\"] = data[\"기존컬럼명\"].dt.date \n",
    "# 기존컬럼에 있는 datetime형식의 날짜를 년월일로 신컬럼에 저장\n",
    "\n",
    "# df[\"신컬럼명\"] = data[\"기존컬럼명\"].dt.year \n",
    "# 기존컬럼에 있는 datetime형식의 날짜를 연(숫자4자리)만 신컬럼에 저장\n",
    "\n",
    "# df[\"신컬럼명\"] = data[\"기존컬럼명\"].dt.month \n",
    "# 기존컬럼에 있는 datetime형식의 날짜를 월(숫자)만 신컬럼에 저장\n",
    "\n",
    "# df[\"신컬럼명\"] = data[\"기존컬럼명\"].dt.month_name \n",
    "# 기존컬럼에 있는 datetime형식의 날짜를 월(문자)만 신컬럼에 저장\n",
    "\n",
    "# df[\"신컬럼명\"] = data[\"기존컬럼명\"].dt.day\n",
    "# 기존컬럼에 있는 datetime형식의 날짜를 일(숫자)만 신컬럼에 저장\n",
    "\n",
    "# 같은 방법으로 dt.hour, dt.minute, dt.second로 시(숫자)/분(숫자)/초(숫자) 나눌 수 있다\n",
    "\n",
    "# dt.weekday 요일(숫자) > 월=0~일6 = dayofweek\n",
    "\n",
    "# dt.quater 분기(숫자), dt.day_name() 요일이름(문자) = day_name(), \n",
    "# dt.weekofyear 연 기준 몇 주째(숫자), dt.dayofyear 연 기준 몇 일째(숫자)\n",
    "# dt.days_in_month 월 일수(숫자) = dayismonth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 날짜 컬럼을 datetime 형식으로 변환\n",
    "# fine_dust['date'] = pd.to_datetime(fine_dust['date'])\n",
    "\n",
    "# # 연도, 계절, 평일/주말 정보 추가\n",
    "# fine_dust['year'] = fine_dust['date'].dt.year\n",
    "# fine_dust['weekday'] = np.where(fine_dust['date'].dt.dayofweek < 5, 'weekday', 'weekend')\n",
    "\n",
    "# # 등급과 평일/주말에 따른 데이터 수 세기\n",
    "# count_data = fine_dust.groupby(['grade', 'weekday']).size().unstack().fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fine_dust에 day컬럼을 추가해서 평일/주말(+공휴일)로 값주는 방법\n",
    "- 공휴일 데이터프레임 hd합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법1 - 람다해서 일대일매칭해서 맞으면 공휴일및 주말항목으로 넣기\n",
    "# 방법2 - merge or join merge에 how 가 있음, 이거로 inner join\n",
    "# - merge로 컬럼 붙임. 그다음 판단 left outer join 으로 공휴일 넣기 \n",
    "# - 컬럼 추가 + 평일/주말 컬럼도 있음 요 두 컬럼을 조합해서 있으면 휴일 아니면 평일\n",
    "\n",
    "# hd[\"date\"]를 fine_dust[\"hd_date\"] 컬럼으로 추가\n",
    "# 이거 할 때 merge 활용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hd[\"dateName\"]의 값을 있으면 weekend, 없다면 day컬럼의 값을 따라 쓰고 병합하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 방법1 - step by step으로 하기\n",
    "\n",
    "# x1 = merge_date['dateName'].map(lambda v: str(v) != 'nan')\n",
    "# 병합한 데이터 프레임의 dateName의 값을 문자열로 바꾸고, nan이 아닌 것만 x1에 넣기\n",
    "\n",
    "# merge_date['day2'] = merge_date['day']\n",
    "# 병합한 데이터 프레임에 day2컬럼을 만들어서 day의 값을 넣기\n",
    "\n",
    "# merge_date[x1] = 'weekend'\n",
    "# x1시리즈에 true인 값을 weekend로 바꾸기\n",
    "\n",
    "# merge_date[merge_date[\"day2\"] =='weekend']\n",
    "# x1의 weekend값을 day2에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법 2 - apply활용\n",
    "\n",
    "# merge_date.iloc[:5, :].apply(lambda row : print(row), axis=1)\n",
    "# 병합한 df의 [0~5행, 전체열]에 apply적용해서 출력하기, axis=1이면 행으로 적용한다.\n",
    "        # date              2021-01-01 00:00:00\n",
    "        # fine_dust(㎍/㎥)                   36.0\n",
    "        # grade                          normal\n",
    "        # day                           weekday\n",
    "        # dateName                         1월1일\n",
    "        # Name: 0, dtype: object\n",
    "        # date              2021-01-02 00:00:00\n",
    "        # fine_dust(㎍/㎥)                   43.0\n",
    "        # grade                          normal\n",
    "        # day                           weekend\n",
    "        # dateName                          NaN\n",
    "        # Name: 1, dtype: object\n",
    "# 이렇게 출력되는데, 아래 형식처럼 나오는 것이다.\n",
    "# 행1의 정보를 컬럼명1 값1 \\ 컬럼명2 값2 \\ ... \n",
    "# 행2의 정보를 컬럼명1 값1 \\ 컬럼명2 값2 \\ ...\n",
    "\n",
    "# date_name2 = merge_date.apply(lambda row : 'weekend' \n",
    "#                               if str(row['dateName']) != 'nan' else row['day'], axis=1)\n",
    "    # date_name2 시리즈를 생성\n",
    "    # 병합된 df에 apply를 lambda를 활용해서 적용\n",
    "    # 1. dateName컬럼을 문자열로 데이터 타입 바꾸기 (NaN > 'nan')\n",
    "    # 2. 행별로 dateName이 'nan'이 아니라면 'weekend' 값을 date_name2 시리즈에 넣기\n",
    "    # 3. 'nan'이라면 day컬럼의 값을 대입해서 date_name2 시리즈에 넣기\n",
    "\n",
    "# merge_date['day2'] = date_name2\n",
    "# 병합된 df에 day2라는 컬럼을 만들어서 위에서 만든 date_name2 시리즈의 값을 넣기\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "함수를 이용해서 계절 구분하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 계절 구분하기 (봄: 3~5, 여름: 6~8, 가을: 9~11, 겨울: 12~2)\n",
    "# def get_season(month):\n",
    "#     if month in [3, 4, 5]:\n",
    "#         return 'Spring'\n",
    "#     elif month in [6, 7, 8]:\n",
    "#         return 'Summer'\n",
    "#     elif month in [9, 10, 11]:\n",
    "#         return 'Fall'\n",
    "#     else:\n",
    "#         return 'Winter'\n",
    "\n",
    "# fine_dust['season'] = fine_dust['date'].dt.month.apply(get_season)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 등급 순서 정의\n",
    "# grade_categories = ['good', 'normal', 'bad', 'very_bad']  # 원하는 순서\n",
    "# grade_order = pd.CategoricalDtype(categories=grade_categories, ordered=True)\n",
    "# season_order = pd.CategoricalDtype(categories=['Spring', 'Summer', 'Fall', 'Winter'], ordered=True)\n",
    "\n",
    "# # 데이터프레임의 grade 열을 순서가 있는 카테고리형으로 변환\n",
    "# fine_dust['grade'] = fine_dust['grade'].astype(grade_order)\n",
    "# fine_dust['season'] = fine_dust['season'].astype(season_order)\n",
    "\n",
    "# # 데이터 그룹화\n",
    "# grouped_data = fine_dust.groupby(['year', 'season', 'grade']).size().unstack(fill_value=0)\n",
    "\n",
    "# # 원하는 순서대로 컬럼 재정렬\n",
    "# grouped_data = grouped_data[grade_categories]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "범주화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 순서가 있는 범주형 지정 방법\n",
    "# from pandas.api.types import CategoricalDtype\n",
    "# categori1 = ['값1', '값2', '값3']     # 이때, 범주의 순서가 값1 > 값2 > 값3으로 지정된다\n",
    "# c_d1 = CategoricalDtype(categories = categori1, ordered = True)\n",
    "# df[\"범주1을 지정하고싶은 컬럼이름\"] = df[\"범주1을 지정하고싶은 컬럼이름\"].astype(c_d1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그룹화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그룹화 예시\n",
    "# df.groupby('class') # class컬럼을 기준으로 그룹화\n",
    "# df.groupby('class').count() # class 컬럼을 기준으로 그룹화한 뒤 타 컬럼별로 not null 개수 세기\n",
    "\n",
    "# group_ex = df.groupby('class').count()\n",
    "# group_ex.loc[1, 'name'] # 1반의 'name' column 유효 element 개수, 4가 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 데이터 그룹화\n",
    "# # grouped_data = fine_dust.groupby(['year', 'season', 'grade']).size().unstack(fill_value=0)\n",
    "# 윗 줄 코드는 from GPT\n",
    "\n",
    "# # 단일 컬럼을 대상으로 그룹\n",
    "# m_fine_dust.groupby('merge_day') # 평일/주말(+공휴일) 두 그룹으로 나누기\n",
    "# m_fine_dust.groupby('merge_day').count()  # day그룹을 기준으로 not null 값 개수 세기\n",
    "\n",
    "# gr = m_fine_dust.groupby('merge_day').count()\n",
    "# gr.loc['weekday', 'grade']\n",
    "# # 평일/주말 두 그룹을 만들어서 gr에 저장 후, 그룹 weekday(평일)의 'grade'column 유효 개수 세기 # 902개\n",
    "\n",
    "# m_fine_dust.groupby('grade')['fine_dust(㎍/㎥)'].mean()\n",
    "# # grade컬럼의 4개 값을 기준으로 그룹한 뒤, 각 그룹의 미세먼지 농도 평균 계산\n",
    "\n",
    "# # 다중 컬럼을 대상으로 그룹\n",
    "# m_fine_dust.groupby(['merge_day', 'grade']).count()\n",
    "# # 평일/주말을 대상으로 그룹한 뒤, 각 그룹 안에서 등급별로 4개를 다시 그룹 > 총 8개 그룹 탄생\n",
    "# # 그 8개 그룹을 대상으로 유효한 값(not null) 개수 세기\n",
    "\n",
    "# pd.DataFrame(m_fine_dust.groupby(['merge_day', 'grade'])['fine_dust(㎍/㎥)'].mean()). \\\n",
    "#                                         sort_values(by = 'fine_dust(㎍/㎥)', ascending = False)\n",
    "# # 평일/주말 그룹 후, 각 그룹 안에서 등급별로 재그룹한 뒤, 각 그룹의 농도 컬럼 값 평균내기\n",
    "# # 평균계산 된 농도 컬럼 값을 기준으로 정렬하기 (ascending = False 내림차순)\n",
    "\n",
    "# 예시\n",
    "# df.groupby(['나이', '학과']).count().unstack(fill_value=0).stack()\n",
    "# 나이별 그룹 > 학과별 그룹 \n",
    "# > 해당 그룹 안에서 컬럼의 값들이 없는 경우는 그룹화를 풀어서 0으로 채운후 재그룹화\n",
    "\n",
    "# 그룹화 .count()와 .size()의 차이\n",
    "# count() - 함수로써 NaN을 제외하고 값을 계산\n",
    "# size() - 데이터프레임의 속성으로써, NaN을 포함하고 계산\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 개별 그룹화 및 분석\n",
    "# gr_season = m_fine_dust.groupby(\"season\")[\"fine_dust(㎍/㎥)\"].mean()\n",
    "# gr_grade = m_fine_dust.groupby(\"grade\")[\"fine_dust(㎍/㎥)\"].count()\n",
    "\n",
    "# # 그룹 풀기\n",
    "# season_reset = gr_season.reset_index()  # 시즌별 분석 결과가 데이터프레임으로 변환\n",
    "# grade_reset = gr_grade.reset_index()    # 등급별 분석 결과가 데이터프레임으로 변환\n",
    "\n",
    "# # 다시 원하는 방식으로 그룹화 가능\n",
    "# 예시: 계절별 평균과 등급 분포를 한 번에 보기\n",
    "# season_analysis = m_fine_dust.groupby(\"season\").agg({\n",
    "#     \"fine_dust(㎍/㎥)\": \"mean\",\n",
    "#     \"grade\": \"value_counts\"\n",
    "# })\n",
    "\n",
    "# # 예시: 계절별, 요일별 평균과 개수\n",
    "# season_day_analysis = m_fine_dust.groupby([\"season\", \"merge_day\"]).agg({\n",
    "#     \"fine_dust(㎍/㎥)\": [\"mean\", \"count\"]\n",
    "# })\n",
    "\n",
    "# # 그룹 결과를 데이터프레임으로 변환\n",
    "# result = m_fine_dust.groupby(\"season\")[\"fine_dust(㎍/㎥)\"].mean().reset_index()\n",
    "\n",
    "# # 이제 이 결과로 새로운 분석 가능\n",
    "# new_analysis = result.groupby(...).mean()  # 새로운 그룹화 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 그룹화\n",
    "# # 평일 / 주말 및 공휴일\n",
    "# observed=True를 붙여야 에러 메세지 안 나옴\n",
    "# gr_year = m_fine_dust.groupby(\"year\", observed=True).count()       # 연도별 그룹화\n",
    "# gr_grade = m_fine_dust.groupby(\"grade\", observed=True).count()     # 등급별 그룹화\n",
    "# gr_season = m_fine_dust.groupby(\"season\", observed=True).count()   # 계절별 그룹화\n",
    "# gr_day = m_fine_dust.groupby(\"merge_day\", observed=True).count()   # 평일/주말별 그룹화\n",
    "\n",
    "# 그룹화한 다음 그룹의 계산결과를 DF로 불러와야 reset_index()로 그룹해제 할 수 있다\n",
    "\n",
    "# # 그룹 풀기\n",
    "# grade_reset = gr_grade.reset_index()    # 등급별 분석 결과가 데이터프레임으로 변환\n",
    "# year_reset = gr_year.reset_index()      # 연도별 분석 결과가 데이터프레임으로 변환\n",
    "# season_reset = gr_season.reset_index()  # 계절별 분석 결과가 데이터프레임으로 변환\n",
    "# day_reset = gr_day.reset_index()        # 평/주말별 분석 결과가 데이터프레임으로 변환\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "미세먼지 데이터 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분석 방향\n",
    "\n",
    "# 1. 단일 그룹 분석 (1-1 ~ 1-4)\n",
    "    # 단일 변수에 따른 미세먼지 농도의 변화를 확인하는 기본 \n",
    "    # 평균, 분산, 최대/최소 값, 빈도 등으로 미세먼지 수준의 분포를 파악\n",
    "\n",
    "# 연도별 미세먼지 분석 (1-1)\n",
    "    # 연도별 평균 미세먼지 농도, 최대/최소 농도 계산.\n",
    "    # 연도별로 \"좋음\"부터 \"매우 나쁨\" 등급까지의 빈도 비율.\n",
    "    # 연도별 농도 변화 추이 시각화 (예: 선 그래프).\n",
    "\n",
    "# 등급별 미세먼지 분석 (1-2)\n",
    "    # 각 등급의 평균 농도, 등급별 농도 분포.\n",
    "    # 각 등급의 일수 또는 빈도 비율.\n",
    "    # 등급별로 평균 및 분산 계산 후 Box plot으로 분포 확인.\n",
    "\n",
    "# 계절별 미세먼지 분석 (1-3)\n",
    "    # 계절별 평균 및 분산, 최대/최소 농도 확인.\n",
    "    # 계절별 \"좋음\"에서 \"매우 나쁨\" 등급까지의 비율 비교.\n",
    "    # 계절에 따른 변화 패턴을 선 그래프로 시각화하여 특정 계절의 농도 피크 확인.\n",
    "\n",
    "# 평일/주말 미세먼지 분석 (1-4)\n",
    "    # 평일과 주말의 평균 농도, 각 등급 빈도 비교.\n",
    "    # Box plot으로 평일/주말 농도의 분포 차이 확인.\n",
    "\n",
    "# 2. 2개 변수 조합 분석 (2-1 ~ 2-6)\n",
    "    # 두 변수의 상호작용에 따른 미세먼지 농도 패턴 찾기\n",
    "    # 이때 그룹별 평균, 빈도, 분포 변화 확인\n",
    "\n",
    "# 연도와 등급 (2-1)\n",
    "    # 각 연도별 등급별 평균 농도 및 빈도 변화.\n",
    "    # 특정 등급의 연도별 변화 추세 (예: \"매우 나쁨\" 비율이 증가했는지 여부).\n",
    "\n",
    "# 연도와 계절 (2-2)\n",
    "    # 연도 및 계절별 평균 농도, 분산 확인.\n",
    "    # 계절별 연도 변화 추세 확인 (예: 봄철 미세먼지 농도가 해마다 증가하는지 확인).\n",
    "\n",
    "# 연도와 평일/주말 (2-3)\n",
    "    # 연도별로 평일/주말의 농도 평균 차이 분석.\n",
    "    # 평일/주말 패턴이 연도에 따라 어떻게 달라지는지 추세 확인.\n",
    "\n",
    "# 등급과 계절 (2-4)\n",
    "    # 각 계절에서 등급별 빈도 확인 (예: 봄철에 \"나쁨\" 빈도가 높은지).\n",
    "    # 계절에 따라 특정 등급의 농도가 차이 나는지 확인.\n",
    "\n",
    "# 등급과 평일/주말 (2-5)\n",
    "    # 평일/주말로 등급별 빈도 분석하여 특정 등급이 주말에 더 많은지 확인.\n",
    "    # 등급별 평일과 주말의 평균 농도 차이 확인.\n",
    "\n",
    "# 계절과 평일/주말 (2-6)\n",
    "    # 계절별 평일/주말에 따른 농도 차이 분석.\n",
    "    # 특정 계절에 주말에 더 높은 농도를 보이는지 확인.\n",
    "\n",
    "# 3. 3개 변수 조합 분석 (3-1 ~ 3-3)\n",
    "    # 세 변수의 조합으로 보다 세밀하게 미세먼지 농도 패턴을 파악\n",
    "\n",
    "# 연도, 등급, 계절 (3-1)\n",
    "    # 연도별로 계절과 등급의 빈도를 분석\n",
    "    # 특정 연도의 특정 계절에 특정 등급이 빈번하게 나타나는지 확인.\n",
    "\n",
    "# 연도, 등급, 평일/주말 (3-2)\n",
    "    # 연도별로 평일/주말에 따라 등급이 어떻게 분포하는지 분석.\n",
    "\n",
    "# 등급, 계절, 평일/주말 (3-3)\n",
    "    # 각 계절에서 평일과 주말의 등급 분포 차이 확인.\n",
    "\n",
    "# 4. 4개 변수 조합 분석 (4-1)\n",
    "    # 모든 변수를 고려하여 최종적으로 미세먼지 농도의 패턴을 분석\n",
    "\n",
    "# 연도, 등급, 계절, 평일/주말 (4-1)\n",
    "    # 각 연도, 계절, 평일/주말, 등급에 따른 농도 분포를 분석하여 \n",
    "    # 특정 조건에서 높은 농도를 보이는 패턴을 파악.\n",
    "    # 히트맵 또는 피벗 테이블을 통해 전체 패턴을 시각화하여 \n",
    "    # 특정 조건에서의 농도 분포 확인."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 데이터 분석 방법과 예시\n",
    "\n",
    "# 평균 : .mean()\n",
    "        # # 등급별 미세먼지 농도 평균 계산\n",
    "        # gr_grade_mean = gr_grade[\"fine_dust(㎍/㎥)\"].mean()\n",
    "        # print(gr_grade_mean)\n",
    "\n",
    "# 최대 : .max()\n",
    "        # # 등급별 미세먼지 농도 최대 값\n",
    "        # gr_grade_max = gr_grade[\"fine_dust(㎍/㎥)\"].max()\n",
    "        # print(gr_grade_max)\n",
    "\n",
    "# 최소 : .min()\n",
    "        # # 등급별 미세먼지 농도 최대 값\n",
    "        # gr_grade_min = gr_grade[\"fine_dust(㎍/㎥)\"].min()\n",
    "        # print(gr_grade_min)\n",
    "\n",
    "# 분산 : .var()\n",
    "        # # 등급별 미세먼지 농도 분산 계산\n",
    "        # gr_grade_variance = gr_grade[\"fine_dust(㎍/㎥)\"].var()\n",
    "        # print(gr_grade_variance)\n",
    "      \n",
    "# 빈도 : .size() or count()\n",
    "        # # 등급별 빈도 계산\n",
    "        # gr_grade_frequency = gr_grade.size()\n",
    "        # print(gr_grade_frequency)\n",
    "        # # 특정 컬럼에 대한 등급별 빈도 계산\n",
    "        # gr_grade_count = gr_grade[\"fine_dust(㎍/㎥)\"].count()\n",
    "        # print(gr_grade_count)\n",
    "\n",
    "# 분포변화 : 시각화 - 히스토그램 및 KDE(커널 밀도 추정) 그래프\n",
    "        # 히스토그램\n",
    "        # import matplotlib.pyplot as plt\n",
    "\n",
    "        # # 등급별 미세먼지 농도 분포 시각화\n",
    "        # plt.figure(figsize=(10, 6))\n",
    "        # for grade in m_fine_dust[\"grade\"].unique():\n",
    "        #     subset = m_fine_dust[m_fine_dust[\"grade\"] == grade]\n",
    "        #     plt.hist(subset[\"fine_dust(㎍/㎥)\"], bins=20, alpha=0.5, label=grade)\n",
    "\n",
    "        # plt.title(\"Distribution of Fine Dust Concentration by Grade\")\n",
    "        # plt.xlabel(\"Fine Dust Concentration (㎍/㎥)\")\n",
    "        # plt.ylabel(\"Frequency\")\n",
    "        # plt.legend()\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분석 양식:\n",
    "# 1-1.  분석\n",
    "    # 그룹화\n",
    "    # 별 최대 값 계산\n",
    "    # 별 최소 값 계산\n",
    "    # 별 평균 계산\n",
    "    # 별 분산 계산\n",
    "    # 별 빈도 계산\n",
    "    # 그룹해제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1-1. 연도별 미세먼지 분석\n",
    "\n",
    "# # 연도별 그룹화\n",
    "# gr_year = m_fine_dust.groupby(\"year\", observed=True)\n",
    "\n",
    "# # 연도별 최대 값 계산\n",
    "# gr_year_max = gr_year[\"fine_dust(㎍/㎥)\"].max()\n",
    "\n",
    "# # 연도별 최소 값 계산\n",
    "# gr_year_min = gr_year[\"fine_dust(㎍/㎥)\"].min()\n",
    "\n",
    "# # 연도별 평균 계산\n",
    "# gr_year_mea = gr_year[\"fine_dust(㎍/㎥)\"].mean()\n",
    "\n",
    "# # 연도별 분산 계산\n",
    "# gr_year_var = gr_year[\"fine_dust(㎍/㎥)\"].var()\n",
    "\n",
    "# # 연도별 빈도 계산\n",
    "# gr_year_cou = gr_year[\"fine_dust(㎍/㎥)\"].count()\n",
    "\n",
    "# print( \"\\n연도별 최대 값 : \\n\", gr_year_max)\n",
    "# print( \"\\n연도별 최소 값 : \\n\", gr_year_min)\n",
    "# print( \"\\n연도별 평균 : \\n\", gr_year_mea)\n",
    "# print( \"\\n연도별 분산 : \\n\", gr_year_var)\n",
    "# print( \"\\n연도별 빈도 : \\n\", gr_year_cou )\n",
    "\n",
    "# # 그룹화 해제\n",
    "# gr_year_max_reset = gr_year_max.reset_index()\n",
    "# gr_year_min_reset = gr_year_min.reset_index()\n",
    "# gr_year_mea_reset = gr_year_mea.reset_index()\n",
    "# gr_year_var_reset = gr_year_var.reset_index()\n",
    "# gr_year_cou_reset = gr_year_cou.reset_index()\n",
    "\n",
    "# 이렇게 길었던 코드가 (심지어 그룹별로 따로 해야함)\n",
    "# def group_analysis_by_single_column(group_col_name, col_name):\n",
    "#     # 그룹화\n",
    "#     grouped_df = m_fine_dust.groupby(group_col_name, observed=True)\n",
    "\n",
    "#     # 그룹별 최대/최소/평균/분산/빈도 계산\n",
    "#     stats = grouped_df[col_name].agg([\"max\", \"min\", \"mean\", \"var\", \"count\"])\n",
    "#     return stats\n",
    "\n",
    "# print( group_analysis_by_single_column(\"year\", \"fine_dust(㎍/㎥)\") )         # 연도별    \n",
    "# print( group_analysis_by_single_column(\"grade\", \"fine_dust(㎍/㎥)\") )        # 등급별    \n",
    "# print( group_analysis_by_single_column(\"season\", \"fine_dust(㎍/㎥)\") )       # 계절별    \n",
    "# print( group_analysis_by_single_column(\"merge_day\", \"fine_dust(㎍/㎥)\") )    # 평일/주말별    \n",
    "\n",
    "# 함수를 써서 이렇게 간소화됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 단일분석 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이게 최초 코드.\n",
    "# 문제 발생 -> 분산만 너무 큼 -> 수정 필요 \n",
    "\n",
    "# # 연도별 통계 시각화\n",
    "# df_year_stats.plot(kind='bar', figsize=(10, 6), title='Yearly Fine Dust Statistics', \n",
    "#                    color=['skyblue', 'salmon', 'lightgreen', 'orange', 'lightcoral'])\n",
    "# plt.ylabel('Values')\n",
    "# plt.xlabel('Year')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.legend(title='Statistics')\n",
    "# plt.grid(axis='y')\n",
    "# plt.show()\n",
    "\n",
    "# # 등급별 통계 시각화\n",
    "# df_grade_stats.plot(kind='bar', figsize=(10, 6), title='Grade-wise Fine Dust Statistics', \n",
    "#                     color=['skyblue', 'salmon', 'lightgreen', 'orange', 'lightcoral'])\n",
    "# plt.ylabel('Values')\n",
    "# plt.xlabel('Grade')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.legend(title='Statistics')\n",
    "# plt.grid(axis='y')\n",
    "# plt.show()\n",
    "\n",
    "# # 계절별 통계 시각화\n",
    "# df_season_stats.plot(kind='bar', figsize=(10, 6), title='Seasonal Fine Dust Statistics', \n",
    "#                      color=['skyblue', 'salmon', 'lightgreen', 'orange', 'lightcoral'])\n",
    "# plt.ylabel('Values')\n",
    "# plt.xlabel('Season')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.legend(title='Statistics')\n",
    "# plt.grid(axis='y')\n",
    "# plt.show()\n",
    "\n",
    "# # 평일/주말별 통계 시각화\n",
    "# df_day_stats.plot(kind='bar', figsize=(10, 6), title='Weekday/Weekend Fine Dust Statistics', \n",
    "#                   color=['skyblue', 'salmon', 'lightgreen', 'orange', 'lightcoral'])\n",
    "# plt.ylabel('Values')\n",
    "# plt.xlabel('Day Type')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.legend(title='Statistics')\n",
    "# plt.grid(axis='y')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_stats_with_count(stats_df, ax, title):\n",
    "#     \"\"\"\n",
    "#     Parameters:\n",
    "#         stats_df: 통계치를 포함한 데이터 프레임\n",
    "#         ax: 서브플롯의 축\n",
    "#         title: 그래프 제목\n",
    "#     \"\"\"\n",
    "#     # 첫 번째 y축에 max, min, mean 플롯\n",
    "#     stats_df[['max', 'min', 'mean']].plot(kind='bar', ax=ax, \n",
    "#                                          color=['skyblue', 'salmon', 'lightgreen'],\n",
    "#                                          width=0.8)\n",
    "    \n",
    "#     # 두 번째 y축 생성\n",
    "#     ax2 = ax.twinx()\n",
    "    \n",
    "#     # count를 선 그래프로 표시\n",
    "#     count_line = ax2.plot(range(len(stats_df)), stats_df['count'], \n",
    "#                          color='sandybrown', marker='o', linewidth=2, \n",
    "#                          label='count')\n",
    "    \n",
    "#     # 첫 번째 축 설정\n",
    "#     ax.set_title(title)\n",
    "#     ax.set_xlabel(stats_df.index.name)\n",
    "#     ax.set_ylabel('Values')\n",
    "#     ax.tick_params(axis='x', rotation=45)\n",
    "#     ax.grid(True, alpha=0.3)\n",
    "    \n",
    "#     # 두 번째 축 설정\n",
    "#     ax2.set_ylabel('Count')\n",
    "#     ax2.tick_params(axis='y', labelcolor='sandybrown')\n",
    "    \n",
    "#     # 범례 통합\n",
    "#     lines1, labels1 = ax.get_legend_handles_labels()\n",
    "#     lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "#     ax2.legend(lines1 + count_line, labels1 + ['count'], \n",
    "#               loc='upper right')\n",
    "\n",
    "# # 서브플롯 생성\n",
    "# fig, axs = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# # 각 서브플롯에 그래프 그리기\n",
    "# plot_stats_with_count(df_year_stats, axs[0, 0], \n",
    "#                      'Yearly Fine Dust Statistics')\n",
    "# plot_stats_with_count(df_grade_stats, axs[0, 1], \n",
    "#                      'Grade-wise Fine Dust Statistics')\n",
    "# plot_stats_with_count(df_season_stats, axs[1, 0], \n",
    "#                      'Seasonal Fine Dust Statistics')\n",
    "# plot_stats_with_count(df_day_stats, axs[1, 1], \n",
    "#                      'Weekday/Weekend Fine Dust Statistics')\n",
    "\n",
    "# # 레이아웃 조정\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 정규화해서 스케일 맞추기 - 고만고만해져서 비교가 어려움\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# def plot_norm_stats(df, title, ylabel, figsize=(10, 6)):\n",
    "#     \"\"\"\n",
    "#     Parameters:\n",
    "#         df: 통계치를 포함한 데이터 프레임\n",
    "#         title: 그래프 제목\n",
    "#         ylabel: y축 레이블\n",
    "#         figsize: 그래프 크기\n",
    "#     \"\"\"\n",
    "#     # 정규화\n",
    "#     norm = MinMaxScaler().fit_transform(df)\n",
    "\n",
    "#     # 정규화된 데이터 프레임으로 변환\n",
    "#     norm_df = pd.DataFrame(norm, columns=df.columns, index=df.index)\n",
    "\n",
    "#     # 정규화된 데이터 시각화\n",
    "#     norm_df.plot(kind='bar', figsize=figsize, title=title, \n",
    "#                  color=['skyblue', 'salmon', 'lightgreen', 'orange'])\n",
    "#     plt.ylabel(ylabel)\n",
    "#     plt.xlabel(df.index.name)\n",
    "#     plt.xticks(rotation=45)\n",
    "#     plt.legend(title='Statistics')\n",
    "#     plt.grid(axis='y')\n",
    "#     plt.show()\n",
    "\n",
    "# # 연도별 통계 시각화 (정규화)\n",
    "# plot_norm_stats(df_year_stats, \n",
    "#                 'Normalized Yearly Fine Dust Stats', 'Normalized Values')\n",
    "\n",
    "# # 등급별 통계 시각화 (정규화)\n",
    "# plot_norm_stats(df_grade_stats, \n",
    "#                 'Normalized Grade-wise Fine Dust Stats', 'Normalized Values')\n",
    "\n",
    "# # 계절별 통계 시각화 (정규화)\n",
    "# plot_norm_stats(df_season_stats, \n",
    "#                 'Normalized Seasonal Fine Dust Stats', 'Normalized Values')\n",
    "\n",
    "# # 평일/주말별 통계 시각화 (정규화)\n",
    "# plot_norm_stats(df_day_stats, \n",
    "#                 'Normalized Weekday/Weekend Fine Dust Stats', 'Normalized Values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "human-da-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
